{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 2157,
     "sourceType": "datasetVersion",
     "datasetId": 18
    }
   ],
   "dockerImageVersionId": 30497,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  },
  "colab": {
   "name": "Amazon FineFood Sentiment Classification using KNN",
   "provenance": []
  }
 },
 "nbformat_minor": 0,
 "nbformat": 4,
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T07:06:36.936442Z",
     "start_time": "2024-05-11T07:06:36.932913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "from tempfile import NamedTemporaryFile\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import unquote, urlparse\n",
    "from urllib.error import HTTPError\n",
    "from zipfile import ZipFile\n",
    "import tarfile\n",
    "import shutil"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T07:07:24.764969Z",
     "start_time": "2024-05-11T07:06:37.419658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
    "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
    "# THEN FEEL FREE TO DELETE THIS CELL.\n",
    "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
    "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
    "# NOTEBOOK.\n",
    "\n",
    "\n",
    "import requests\n",
    "from urllib.parse import unquote\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Chuỗi URL được mã hóa\n",
    "encoded_url = 'https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F18%2F2157%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240510%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240510T171529Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D348640283931f9c4dd02ba0bb5fd66196965d46418636da031b90b545926d07ce5879ed7be696c922ebb5a2b569a62d675549dff761f099a3e2ab79214260854c17c0f650418c8f00d42df510661af656cfd7f70852ee2c1f562763f38d1fa28686f310de50f43f9b123858b7928321fd6ed6185131e98f1949bf312e15b2c4af43abaf4c6deee5b11514e3e1d827d689e83ec88690ad80c61284691561f284f92a160cacc1fabe61159f873033aff1eb001fb5eeba273dcf05851585a4a50b10c27520a0d42b9a7eef9dbae5520f36493457590c3d489ed9b336bfe7fc49a211f3406d3808a2a5aa02de77094be743170f064fd5191a35e98f08ba5b43daccf'\n",
    "\n",
    "# Giải mã URL\n",
    "decoded_url = unquote(encoded_url)\n",
    "\n",
    "# Tên tệp tải xuống\n",
    "file_name = 'reviews.zip'\n",
    "\n",
    "# Thực hiện tải xuống\n",
    "response = requests.get(decoded_url, stream=True)\n",
    "total_size = int(response.headers.get('content-length', 0))\n",
    "\n",
    "with open(file_name, 'wb') as file:\n",
    "    with tqdm(total=total_size, unit='B', unit_scale=True, desc=\"Downloading\", ascii=True) as pbar:\n",
    "        for data in response.iter_content(chunk_size=4096):\n",
    "            file.write(data)\n",
    "            pbar.update(len(data))\n",
    "\n",
    "print('Data source import complete')\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|##########| 254M/254M [00:46<00:00, 5.44MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data source import complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Unzip "
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T07:16:17.401685Z",
     "start_time": "2024-05-11T07:16:04.818189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "zip_file_path=\"reviews.zip\"\n",
    "extract_dir_path=\"/input\"\n",
    "with ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir_path)\n",
    "    print(\"Extracting done\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting done\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "\n",
    "The Amazon Fine Food Reviews dataset consists of reviews of fine foods from Amazon. The data span a period of more than 10 years, including all ~500,000 reviews up to October 2012. Reviews include product and user information, ratings, and a plaintext review.\n",
    "\n",
    "The dataset contains the following columns:\n",
    "\n",
    "1. productId: The product ID of the reviewed item.\n",
    "2. userId: The user ID of the reviewer.\n",
    "3. profileName: The name of the reviewer's profile.\n",
    "4. helpfulness: The number of helpful votes the review received.\n",
    "5. score: The rating of the product (1-5 stars).\n",
    "6. time: The date and time of the review.\n",
    "7. summary: A short summary of the review.\n",
    "8. text: The full text of the review.\n",
    "\n",
    "The dataset can be used for a variety of purposes, such as:\n",
    "1. Sentiment analysis: To determine the overall sentiment of the reviews (positive, negative, or neutral).\n",
    "2. Topic modeling: To identify the topics that are discussed in the reviews.\n",
    "3. Product recommendation: To recommend products to users based on their reviews.\n",
    "4. Spam detection: To identify and remove spam reviews.\n",
    "\n",
    "The Amazon Fine Food Reviews dataset is a valuable resource for anyone interested in understanding consumer behavior and the online review process. It is a large and comprehensive dataset that can be used to answer a variety of research questions."
   ],
   "metadata": {
    "id": "nREJVLISgMN-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ***Project Objective: Examining the outcomes of sentiment analysis in review polarity classification by employing K-nearest neighbors (KNN) across Bag of Words, TFIDF, and Word2Vector representations.***\n",
    "\n",
    "#### ***Description:*** This project aims to analyze the sentiment of reviews by implementing a review polarity classification system. We will compare the performance of three different feature representations, namely Bag of Words, TFIDF, and Word2Vector. The evaluation will be conducted using the K-nearest neighbors (KNN) algorithm to determine the effectiveness of each representation in classifying review sentiments accurately.\n",
    "\n",
    "\n",
    "#### ***Steps:***\n",
    "1. Import necessary libraries\n",
    "2. Data Cleaning and Storing the cleaned reviews in a new database\n",
    "3. Convert reviews into vectors (Bag of Words, Tf-Idf, Word2Vec) and sentiment classification using KNN\n",
    "4. Conclusion"
   ],
   "metadata": {
    "id": "iyqX_sRBgMN_"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Importing Libraries and Data"
   ],
   "metadata": {
    "id": "3ru7UeUHgMN_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "import os\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.manifold import TSNE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T05:58:53.920101Z",
     "iopub.execute_input": "2024-02-11T05:58:53.921348Z",
     "iopub.status.idle": "2024-02-11T05:58:57.837639Z",
     "shell.execute_reply.started": "2024-02-11T05:58:53.921298Z",
     "shell.execute_reply": "2024-02-11T05:58:57.836506Z"
    },
    "trusted": true,
    "id": "x9lFDFdtgMN_",
    "ExecuteTime": {
     "end_time": "2024-05-11T07:07:50.900341Z",
     "start_time": "2024-05-11T07:07:50.790698Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mseaborn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msns\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'pandas'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "trusted": true,
    "id": "ea7P8OEVgMN_"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# opening a connection to database\n",
    "con = sqlite3.connect('input/database.sqlite')\n",
    "\n",
    "# querying database to get filtered data without 3 star review\n",
    "# we are not considering the reviews with value of 3 as it is not a good indicator of polarity of review\n",
    "data = pd.read_sql_query('SELECT * FROM Reviews WHERE Score !=3', con)\n",
    "print(data.shape)\n",
    "data.head(3)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T05:58:57.84128Z",
     "iopub.execute_input": "2024-02-11T05:58:57.841826Z",
     "iopub.status.idle": "2024-02-11T05:59:10.583546Z",
     "shell.execute_reply.started": "2024-02-11T05:58:57.841778Z",
     "shell.execute_reply": "2024-02-11T05:59:10.582398Z"
    },
    "trusted": true,
    "id": "mWbo9SrNgMN_"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will use the score column provided to get the polarity of the review.\n",
    "1. reviews with score 4 and 5 will be considered positive\n",
    "2. reviews with score 1 and 2 will be considered negative\n",
    "3. we have dropped the reviews with value of 3 as it is not a good indicator of polarity of review"
   ],
   "metadata": {
    "id": "tO5YNAYHgMOA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# convert score values to sentiment\n",
    "def score_to_sentiment(x):\n",
    "    if x > 3:\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return 'negative'\n",
    "\n",
    "data['Score'] = data['Score'].apply(score_to_sentiment)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T05:59:10.585281Z",
     "iopub.execute_input": "2024-02-11T05:59:10.586024Z",
     "iopub.status.idle": "2024-02-11T05:59:10.763077Z",
     "shell.execute_reply.started": "2024-02-11T05:59:10.585982Z",
     "shell.execute_reply": "2024-02-11T05:59:10.762214Z"
    },
    "trusted": true,
    "id": "ob12z746gMOA"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Data Cleaning\n",
    "\n",
    "Steps:\n",
    "1. Sorting Data by ProductID\n",
    "2. Deduplication\n",
    "3. Helpfulness numerator should always be less than helpfulness denominator\n",
    "4. Cleaning HTML Tags and Punctuation"
   ],
   "metadata": {
    "id": "V8CAT-X5gMOA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Sorting data acc to product ID\n",
    "sorted_data = data.sort_values(by='ProductId', axis=0, ascending=True, kind='quicksort', na_position='last')\n",
    "\n",
    "# Deduplication\n",
    "final = sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n",
    "\n",
    "# helpfulness numerator should always be less than helpfulness denominator\n",
    "final = final[final['HelpfulnessNumerator'] <= final['HelpfulnessDenominator']]\n",
    "print('Shape of our data remaining:', final.shape)\n",
    "\n",
    "# checking the percentage of data remaining\n",
    "print('Percentage of Data Remaining:', (final.shape[0] / data.shape[0]) * 100)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T05:59:10.765367Z",
     "iopub.execute_input": "2024-02-11T05:59:10.765922Z",
     "iopub.status.idle": "2024-02-11T05:59:13.874146Z",
     "shell.execute_reply.started": "2024-02-11T05:59:10.765893Z",
     "shell.execute_reply": "2024-02-11T05:59:13.872936Z"
    },
    "trusted": true,
    "id": "LuB9W9hPgMOA"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# let's check how positive and negative reviews are distributed\n",
    "plt.bar(final['Score'].value_counts().index, final['Score'].value_counts().values)\n",
    "plt.xlabel('index')\n",
    "plt.ylabel('Score')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T05:59:13.876198Z",
     "iopub.execute_input": "2024-02-11T05:59:13.87676Z",
     "iopub.status.idle": "2024-02-11T05:59:14.184985Z",
     "shell.execute_reply.started": "2024-02-11T05:59:13.876709Z",
     "shell.execute_reply": "2024-02-11T05:59:14.183728Z"
    },
    "trusted": true,
    "id": "TEBVkWLNgMOA"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# find sentences containing HTML tags and punctuation\n",
    "# we can see that there are a lot of unwanted elements in the raw text provided to us\n",
    "# these elements will cause unnecessary dimensions in our vector conversions.\n",
    "import re\n",
    "i=0\n",
    "for sent in final['Text'].values:\n",
    "    if (len(re.findall('<.*?>', sent))) and (len(re.findall('[?|!|\\'|\"|#]', sent))):\n",
    "        print('Index:', i)\n",
    "        print(sent)\n",
    "        break\n",
    "    i += 1"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T05:59:14.186417Z",
     "iopub.execute_input": "2024-02-11T05:59:14.186737Z",
     "iopub.status.idle": "2024-02-11T05:59:14.195198Z",
     "shell.execute_reply.started": "2024-02-11T05:59:14.18671Z",
     "shell.execute_reply": "2024-02-11T05:59:14.193799Z"
    },
    "trusted": true,
    "id": "3f2KLc41gMOA"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# source ->\n",
    "# 1. https://stackoverflow.com/questions/9662346/python-code-to-remove-html-tags-from-a-string\n",
    "# 2. https://datagy.io/python-remove-punctuation-from-string/\n",
    "\n",
    "stop = set(stopwords.words('english')) #set of stopwords\n",
    "sno = nltk.stem.SnowballStemmer('english') #initialising the snowball stemmer\n",
    "\n",
    "#function to clean the word of any html-tags\n",
    "def cleanhtml(sentence):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "\n",
    "# function to clean the word of any punctuation or special characters\n",
    "# please note that you can add any missed character using | operator\n",
    "def cleanpunc(sentence):\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#|.|,|)|(|\\|/]',r'',sentence)\n",
    "    return  cleaned\n",
    "\n",
    "res = cleanhtml(final['Text'].values[6])\n",
    "res = cleanpunc(res)\n",
    "print(res)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T05:59:14.197155Z",
     "iopub.execute_input": "2024-02-11T05:59:14.197847Z",
     "iopub.status.idle": "2024-02-11T05:59:14.214819Z",
     "shell.execute_reply.started": "2024-02-11T05:59:14.197799Z",
     "shell.execute_reply": "2024-02-11T05:59:14.213842Z"
    },
    "trusted": true,
    "id": "TsGmsPZ_gMOA"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# làm sạch html, dấu câu, từ dừng và bắt nguồn từng từ trong mỗi bài đánh giá\n",
    "# xin lưu ý rằng đối với Word2Vec, sẽ không bao gồm tất cả các bước này để xử lý trước.\n",
    "# lưu trữ những đánh giá cuối cùng này trong cơ sở dữ liệu Final.sqlite\n",
    "\n",
    "if not os.path.isfile('final.sqlite'):\n",
    "    cleaned_reviews=[]\n",
    "    cleaned_reviews_w2v = []\n",
    "    for i, sent in enumerate(tqdm(final['Text'].values)):\n",
    "        filtered_sentence=[]\n",
    "        filtered_sentence_w2v = []\n",
    "        sent = cleanhtml(sent)\n",
    "        for word in sent.split():\n",
    "            for cleaned_words in cleanpunc(word).split():\n",
    "                if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):\n",
    "                    filtered_sentence_w2v.append(cleaned_words.lower())\n",
    "                    if(cleaned_words.lower() not in stop):\n",
    "                        stem_word=(sno.stem(cleaned_words.lower())).encode('utf8')\n",
    "                        filtered_sentence.append(stem_word)\n",
    "        filtered_sentence = b' '.join(filtered_sentence)\n",
    "        filtered_sentence_w2v = ' '.join(filtered_sentence_w2v)\n",
    "        cleaned_reviews.append(filtered_sentence)\n",
    "        cleaned_reviews_w2v.append(filtered_sentence_w2v)\n",
    "    final['CleanedText']=cleaned_reviews\n",
    "    final['CleanedText']=final['CleanedText'].str.decode(\"utf-8\")\n",
    "    final['CleanedText_w2v'] = cleaned_reviews_w2v\n",
    "\n",
    "    conn = sqlite3.connect('final.sqlite')\n",
    "    c=conn.cursor()\n",
    "    conn.text_factory = str\n",
    "    final.to_sql('Reviews', conn,  schema=None, if_exists='replace', \\\n",
    "                 index=True, index_label=None, chunksize=None, dtype=None)\n",
    "    conn.close()\n",
    "    print('Done..!!')\n",
    "\n",
    "else:\n",
    "    print('File already Exist')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T05:59:14.21643Z",
     "iopub.execute_input": "2024-02-11T05:59:14.217063Z",
     "iopub.status.idle": "2024-02-11T06:07:04.031922Z",
     "shell.execute_reply.started": "2024-02-11T05:59:14.217032Z",
     "shell.execute_reply": "2024-02-11T06:07:04.0305Z"
    },
    "trusted": true,
    "id": "kypm-pXfgMOA"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# creating a function to visualize tsne results\n",
    "\n",
    "def tsne_visualizer(data, label, title):\n",
    "    # TSNE\n",
    "    from sklearn.manifold import TSNE\n",
    "\n",
    "    tsne_model = TSNE(n_components=2, n_iter=2000)\n",
    "    tsne_data = tsne_model.fit_transform(data)\n",
    "\n",
    "    tsne_df = pd.DataFrame(data=np.vstack((tsne_data.T, label)).T, columns=['1st_component', '2nd_component', 'label'])\n",
    "    tsne_df\n",
    "\n",
    "    sns.scatterplot(data=tsne_df, x='1st_component', y='2nd_component', hue='label')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# tsne_visualizer(data=bow_standerdised_data, label=df_final['Score'].values)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:07:04.033845Z",
     "iopub.execute_input": "2024-02-11T06:07:04.034229Z",
     "iopub.status.idle": "2024-02-11T06:07:04.042444Z",
     "shell.execute_reply.started": "2024-02-11T06:07:04.034199Z",
     "shell.execute_reply": "2024-02-11T06:07:04.041057Z"
    },
    "trusted": true,
    "id": "or3uyP0tgMOB"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Chuyển đổi đánh giá thành vectơ và phân loại cảm xúc bằng KNN\n",
    "\n",
    "### ***Mục tiêu:*** Chuyển đổi từng đánh giá hoặc câu thành một vectơ và sử dụng K Nearest Neighbor để phân loại."
   ],
   "metadata": {
    "id": "d1WD_BIAgMOB"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Trong phần này, chúng tôi sẽ chuyển đổi các đánh giá đã được làm sạch của mình thành vectơ bằng cách sử dụng ***Bag Of Words, TF-IDF, Average Word2Vec và TF-IDF Weighted*** Word2Vec để chúng tôi có thể biểu diễn chúng trong mặt phẳng n chiều và sau đó sử dụng Knearest Hàng xóm để phân loại các đánh giá tích cực và tiêu cực.\n",
    "\n",
    "\n",
    "Dưới đây là các bước chúng tôi sẽ thực hiện cho từng kỹ thuật vector hóa:\n",
    "1. Vector hóa: BOW, TF-IDF, Avg Word2Vec, Word2Vec có trọng số TF-IDF\n",
    "2. Lấy mẫu quá mức: Lấy mẫu ngẫu nhiên\n",
    "3. Tiêu chuẩn hóa\n",
    "4. Giảm kích thước: PCA ; (sẽ bị bỏ qua đối với Word2Vec)\n",
    "5. K-NN và Báo cáo phân loạiv"
   ],
   "metadata": {
    "id": "2GFt2ljOgMOB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# đọc các dữ liệu đã làm sạch trong final\n",
    "\n",
    "if os.path.isfile('final.sqlite'):\n",
    "    conn = sqlite3.connect('final.sqlite')\n",
    "    final = pd.read_sql_query(\"\"\" SELECT * FROM Reviews \"\"\", conn)\n",
    "    conn.close()\n",
    "else:\n",
    "    print(\"File Not Available in the location\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:07:04.049458Z",
     "iopub.execute_input": "2024-02-11T06:07:04.050085Z",
     "iopub.status.idle": "2024-02-11T06:07:08.856257Z",
     "shell.execute_reply.started": "2024-02-11T06:07:04.050031Z",
     "shell.execute_reply": "2024-02-11T06:07:08.855036Z"
    },
    "trusted": true,
    "id": "maS1dymwgMOB"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (A) Bag Of Words"
   ],
   "metadata": {
    "id": "nSPtyoOMgMOB"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Phân chia dựa trên thời gian\n",
    "Phân tách dựa trên thời gian đề cập đến việc thực hành phân chia dữ liệu hoặc mẫu dựa trên tiêu chí thời gian. Mục tiêu chính của việc phân tách dựa trên thời gian là đảm bảo rằng thứ tự thời gian của dữ liệu được giữ nguyên trong quá trình phân tách. Bằng cách sử dụng tính năng phân tách dựa trên thời gian, các mô hình học máy có thể được đào tạo và đánh giá dựa trên dữ liệu gần giống với kịch bản trong thế giới thực mà chúng sẽ được triển khai. Cách tiếp cận này giúp nắm bắt các mô hình thời gian và sự phụ thuộc, đồng thời cung cấp ước tính đáng tin cậy về hiệu suất của mô hình trong các ứng dụng thực tế.\n",
    "\n",
    "Các bước:\n",
    "1. Sắp xếp dữ liệu theo thời gian\n",
    "2. Tách dữ liệu đã sắp xếp của tôi thành dữ liệu huấn luyện, dữ liệu xác thực và dữ liệu kiểm tra. sẽ lấy 70% dữ liệu đầu tiên để đào tạo và xác thực, phần còn lại để kiểm tra."
   ],
   "metadata": {
    "id": "LMgZRlAIgMOB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# sắp xếp dữ liệu theo thời gian vì nó là một biểu diễn tốt hơn của trường hợp sử dụng thực tế\n",
    "\n",
    "# hãy thao tác trên 7000 điểm dữ liệu vì hạn chế bộ nhớ\n",
    "df_final = final.sort_values(by='Time')[:7000]\n",
    "print('hình dạng của tập dữ liệu cuối cùng :', df_final.shape)\n",
    "print(\"=\"*20)\n",
    "\n",
    "# lấy 70 phần trăm dữ liệu của chúng tôi cho train và 30 phần trăm cho test\n",
    "# của 70 phần trăm dữ liệu, chúng tôi sẽ sử dụng 80 phần trăm cho train và 20 phần trăm cho cross validation\n",
    "n_train = int(np.ceil(df_final.shape[0] * 0.70))\n",
    "n_cv = int(n_train * 0.80)\n",
    "\n",
    "df_train = df_final[:n_cv]\n",
    "df_cv = df_final[n_cv:n_train]\n",
    "df_test = df_final[n_train:]\n",
    "\n",
    "# kiểm tra phân phối lớp của mỗi phần dữ liệu\n",
    "df_lst = [('\\tDữ liệu Train', df_train), ('\\tDữ liệu Cross Validation', df_cv), ('\\tDữ liệu Test ', df_test)]\n",
    "for df_name, df in df_lst:\n",
    "    print(df_name)\n",
    "    print('Hình dạng của dữ liệu:', df.shape)\n",
    "    print('Phân phối lớp:')\n",
    "    print(df['Score'].value_counts())\n",
    "    print('='*20)\n",
    "\n",
    "#vẽ biểu đồ số lượng điểm dữ liệu trong mỗi lớp\n",
    "sns.countplot(df_final['Score'])\n",
    "plt.show()\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:07:08.857856Z",
     "iopub.execute_input": "2024-02-11T06:07:08.858247Z",
     "iopub.status.idle": "2024-02-11T06:07:09.262536Z",
     "shell.execute_reply.started": "2024-02-11T06:07:08.858214Z",
     "shell.execute_reply": "2024-02-11T06:07:09.261074Z"
    },
    "trusted": true,
    "id": "Z5JLvSHJgMOB"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vectorization using Bag Of Words"
   ],
   "metadata": {
    "id": "TNEEYxomgMOB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Bag of Words\n",
    "vectorizer_bow = CountVectorizer()\n",
    "train_bow = vectorizer_bow.fit_transform(df_train['CleanedText'].values)\n",
    "cv_bow = vectorizer_bow.transform(df_cv['CleanedText'].values)\n",
    "test_bow = vectorizer_bow.transform(df_test['CleanedText'].values)\n",
    "\n",
    "print(train_bow.shape)\n",
    "print(cv_bow.shape)\n",
    "print(test_bow.shape)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:07:09.264192Z",
     "iopub.execute_input": "2024-02-11T06:07:09.26463Z",
     "iopub.status.idle": "2024-02-11T06:07:09.711569Z",
     "shell.execute_reply.started": "2024-02-11T06:07:09.264597Z",
     "shell.execute_reply": "2024-02-11T06:07:09.710435Z"
    },
    "trusted": true,
    "id": "TKnfejNTgMOB"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Oversampling\n",
    "Các bộ dữ liệu không cân bằng, trong đó các lớp không được thể hiện như nhau, có thể đặt ra những thách thức trong các nhiệm vụ học máy. Chúng tôi có số lượng đánh giá tiêu cực thấp đáng kể so với đánh giá tích cực và chúng tôi sẽ sử dụng Lấy mẫu ngẫu nhiên để giải quyết vấn đề này.\n",
    "\n",
    "RandomOverSampler: RandomOverSampler hoạt động bằng cách sao chép ngẫu nhiên các ví dụ từ lớp thiểu số cho đến khi nó đạt kích thước tương tự như lớp đa số. Kỹ thuật lấy mẫu tổng hợp này giúp giảm thiểu vấn đề mất cân bằng lớp, cho phép mô hình học hỏi từ cách biểu diễn dữ liệu cân bằng hơn."
   ],
   "metadata": {
    "id": "1-0snTy-gMOB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# vẽ biểu đồ mất cân bằng lớp trước khi thực hiện oversampling\n",
    "plt.figure(1, figsize=(17,6))  # Tạo một hình vẽ mới với kích thước 17x6\n",
    "plt.subplot(1,2,1)  # Tạo một subplot với 1 hàng, 2 cột, và sử dụng ô thứ nhất\n",
    "sns.countplot(x=df_train['Score'])  # Vẽ biểu đồ đếm số lượng mẫu trong mỗi lớp của dữ liệu huấn luyện trước khi thực hiện oversampling\n",
    "plt.title('Phân phối lớp trước khi oversampling')  #\n",
    "print('Hình dạng của dữ liệu trước khi oversampling:', train_bow.shape, '\\n\\n') \n",
    "\n",
    "# thực hiện oversampling bằng cách sử dụng SMOTE\n",
    "# oversampling dữ liệu huấn luyện của chúng tôi\n",
    "ros = RandomOverSampler()  # Khởi tạo một instance của RandomOverSampler\n",
    "X_train_bow, Y_train_bow = ros.fit_resample(train_bow,df_train['Score'])  # Thực hiện oversampling dữ liệu huấn luyện bằng phương pháp Random Over-Sampling (ROS)\n",
    "\n",
    "# vẽ biểu đồ phân phối lớp sau khi oversampling\n",
    "plt.subplot(1,2,2)  # Chuyển sang ô subplot thứ hai\n",
    "sns.countplot(x=Y_train_bow)  # Vẽ biểu đồ đếm số lượng mẫu trong mỗi lớp sau khi thực hiện oversampling\n",
    "plt.title('Phân phối lớp sau khi oversampling')  \n",
    "plt.show()  \n",
    "print('Hình dạng của dữ liệu sau khi oversampling:', X_train_bow.shape)  # In ra hình dạng của dữ liệu sau khi thực hiện oversampling\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:07:09.712893Z",
     "iopub.execute_input": "2024-02-11T06:07:09.713224Z",
     "iopub.status.idle": "2024-02-11T06:07:10.260432Z",
     "shell.execute_reply.started": "2024-02-11T06:07:09.713195Z",
     "shell.execute_reply": "2024-02-11T06:07:10.258962Z"
    },
    "trusted": true,
    "id": "q5E1-OPdgMOB"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Standardization (Tiêu chuẩn hoá)",
   "metadata": {
    "id": "34mkrpN4gMOB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# standardization\n",
    "scaler_bow = StandardScaler()\n",
    "X_train_bow_standardised = scaler_bow.fit_transform(X_train_bow.toarray())\n",
    "X_cv_bow_standardised = scaler_bow.transform(cv_bow.toarray())\n",
    "X_test_bow_standardised = scaler_bow.transform(test_bow.toarray())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:07:10.262613Z",
     "iopub.execute_input": "2024-02-11T06:07:10.263549Z",
     "iopub.status.idle": "2024-02-11T06:07:13.436947Z",
     "shell.execute_reply.started": "2024-02-11T06:07:10.263501Z",
     "shell.execute_reply": "2024-02-11T06:07:13.435736Z"
    },
    "trusted": true,
    "id": "UeY7dsjsgMOB"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Dimensionality Reduction( Giảm kích thước)\n",
    "Giảm kích thước là một kỹ thuật cơ bản trong học máy nhằm mục đích giải quyết vấn đề về kích thước bằng cách giảm số lượng tính năng hoặc biến trong tập dữ liệu. Các bộ dữ liệu chiều cao có thể đưa ra những thách thức như tăng độ phức tạp tính toán, trang bị quá mức và khó khăn trong việc diễn giải và trực quan hóa dữ liệu. Các phương pháp giảm kích thước giúp giảm thiểu những vấn đề này bằng cách trích xuất các tính năng có nhiều thông tin nhất hoặc tạo ra các biểu diễn dữ liệu mới, có chiều thấp hơn.\n",
    "Quá trình vector hóa BOW của chúng tôi đã tạo ra khoảng 11K kích thước cho mỗi vectơ của chúng tôi, chúng tôi sẽ sử dụng PCA để giải quyết vấn đề này."
   ],
   "metadata": {
    "id": "QziF7q5pgMOB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Giảm chiều dữ liệu sử dụng phương pháp PCA hoặc Truncated SVD\n",
    "\n",
    "# Sử dụng PCA với số thành phần chính (components) là 3000\n",
    "pca = PCA(n_components=3000)\n",
    "pca.fit(X_train_bow_standardised)  # Huấn luyện PCA trên dữ liệu huấn luyện đã chuẩn hóa\n",
    "explained_variance = pca.explained_variance_ratio_  # Lấy tỷ lệ phương sai được giải thích bởi mỗi thành phần chính\n",
    "print(len(explained_variance))  # In ra số lượng tỷ lệ phương sai được giải thích\n",
    "\n",
    "# Xác định số chiều cần thiết để giải thích 95% tổng phương sai\n",
    "dim_req_var = sum(np.cumsum(explained_variance) <= 0.95)\n",
    "print('Số chiều cần thiết để giải thích 95% tổng phương sai:', dim_req_var)\n",
    "print('Phương sai được giải thích:', np.cumsum(explained_variance)[dim_req_var])\n",
    "\n",
    "# Vẽ biểu đồ hiển thị phương sai tích lũy theo số chiều\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.grid()\n",
    "plt.plot(list(range(len(explained_variance))), np.cumsum(explained_variance))\n",
    "plt.axvline(x=dim_req_var, color='g', label='Đường 95% phương sai')\n",
    "plt.xlabel('Số chiều')\n",
    "plt.ylabel('Phần trăm Phương sai Tích lũy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Sử dụng PCA để giảm chiều dữ liệu cho dữ liệu huấn luyện, dữ liệu cross validation và dữ liệu kiểm tra\n",
    "X_train_bow_pca = pca.transform(X_train_bow_standardised)[:, :dim_req_var]\n",
    "X_cv_bow_pca = pca.transform(X_cv_bow_standardised)[:, :dim_req_var]\n",
    "X_test_bow_pca = pca.transform(X_test_bow_standardised)[:, :dim_req_var]\n",
    "\n",
    "# Xác định nhãn cho dữ liệu huấn luyện, dữ liệu cross validation và dữ liệu kiểm tra\n",
    "y_train = Y_train_bow\n",
    "y_cv = df_cv['Score'].values\n",
    "y_test = df_test['Score'].values\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:07:13.440629Z",
     "iopub.execute_input": "2024-02-11T06:07:13.441237Z",
     "iopub.status.idle": "2024-02-11T06:09:45.927836Z",
     "shell.execute_reply.started": "2024-02-11T06:07:13.441202Z",
     "shell.execute_reply": "2024-02-11T06:09:45.926234Z"
    },
    "trusted": true,
    "id": "ixuw-YRSgMOB"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### K-Nearest Neighbors\n",
    "\n",
    "K-Nearest Neighbors (KNN) là một thuật toán phổ biến và trực quan được sử dụng cho cả nhiệm vụ phân loại và hồi quy trong học máy. Đây là một thuật toán phi tham số, nghĩa là nó không đưa ra các giả định về phân bổ dữ liệu cơ bản. KNN đưa ra dự đoán dựa trên sự tương đồng giữa các phiên bản trong không gian đặc trưng. Chúng tôi sẽ sử dụng khoảng cách Euclide làm thước đo khoảng cách cho trường hợp sử dụng này.\n",
    "\n",
    "1. Thuật toán K-Nearest Neighbors (KNN) sẽ được thực thi với một phạm vi k giá trị, cụ thể từ 1 đến 29 với kích thước bước là 2, đảm bảo chỉ xem xét các giá trị lẻ.\n",
    "2. Sau đó, mô hình KNN sẽ được huấn luyện bằng cách sử dụng dữ liệu huấn luyện và dữ liệu xác thực sẽ được sử dụng để đánh giá độ chính xác, điểm f1 (dương) và điểm f1 (âm) cho mỗi giá trị của k.\n",
    "3. Giá trị k liên quan đến độ chính xác cao nhất sẽ được chọn và k tối ưu này sẽ được sử dụng để tạo ra số liệu độ chính xác cuối cùng. Ngoài ra, một báo cáo phân loại toàn diện và ma trận nhầm lẫn sẽ được tạo bằng dữ liệu thử nghiệm."
   ],
   "metadata": {
    "id": "TMZFIKo4gMOB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Sử dụng KNN để phân loại dữ liệu\n",
    "accuracy = []\n",
    "f1_positive = []\n",
    "f1_negative = []\n",
    "K_values = list(range(1,30,2))\n",
    "\n",
    "# Vòng lặp qua các giá trị K để tìm ra giá trị tốt nhất\n",
    "for k in tqdm(K_values):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_bow_pca, y_train)\n",
    "    pred = knn.predict(X_cv_bow_pca)\n",
    "    f1_positive.append(f1_score(y_cv, pred, pos_label=\"positive\"))\n",
    "    f1_negative.append(f1_score(y_cv, pred, pos_label=\"negative\"))\n",
    "    accuracy.append(accuracy_score(y_cv, pred))\n",
    "\n",
    "positive_ind = f1_positive.index(max(f1_positive))\n",
    "negative_ind = f1_negative.index(max(f1_negative))\n",
    "acc_ind = accuracy.index(max(accuracy))\n",
    "\n",
    "# In ra kết quả tốt nhất đạt được\n",
    "print('Độ chính xác tối đa là {a} với giá trị K là {b}'.format(a=max(accuracy), b=K_values[acc_ind]))\n",
    "print('F1 score tối đa trên dữ liệu CV cho nhãn positive là {a} với giá trị K là {b}'.format(a=max(f1_positive), b=K_values[positive_ind]))\n",
    "print('F1 score tối đa trên dữ liệu CV cho nhãn negative là {a} với giá trị K là {b}'.format(a=max(f1_negative), b=K_values[negative_ind]))\n",
    "\n",
    "# Vẽ biểu đồ hiển thị accuracy, F1-score cho các giá trị K\n",
    "plt.figure(1, figsize=(22,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(K_values, accuracy, 'o--')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('K_Values')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(K_values, f1_positive, 'o--')\n",
    "plt.title('F1_Positive')\n",
    "plt.xlabel('K_Values')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(K_values, f1_negative, 'o--')\n",
    "plt.title('F1_Negative')\n",
    "plt.xlabel('K_Values')\n",
    "\n",
    "# Huấn luyện mô hình KNN trên dữ liệu kiểm tra và tạo các ma trận liên quan\n",
    "knn = KNeighborsClassifier(n_neighbors=K_values[acc_ind])\n",
    "knn.fit(X_train_bow_pca, y_train)\n",
    "pred = knn.predict(X_test_bow_pca)\n",
    "\n",
    "# Tạo confusion matrix và báo cáo phân loại để đánh giá hiệu suất\n",
    "confusion_mat = pd.DataFrame(confusion_matrix(y_test, pred, labels=['positive', 'negative']), columns=['pred_positive', 'pred_negative'], index=['true_positive', 'true_negative'])\n",
    "print('\\nConfusion matrix:')\n",
    "print(confusion_mat)\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, pred))\n",
    "print('\\nAccuracy on Test Data:', accuracy_score(y_test, pred))\n",
    "\n",
    "#Precision là tỷ lệ giữa số lượng dự đoán chính xác của một lớp và tổng số dự đoán của lớp đó\n",
    "#Recall là tỷ lệ giữa số lượng dự đoán chính xác của một lớp và tổng số điểm thực sự thuộc lớp đó trong dữ liệu.\n",
    "#F1-score là một trung bình điều hòa giữa precision và recall. \n",
    "# Trong trường hợp này, precision và recall cho nhãn negative khá thấp, chỉ khoảng 21% và 9% tương ứng."
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:09:45.930196Z",
     "iopub.execute_input": "2024-02-11T06:09:45.931313Z",
     "iopub.status.idle": "2024-02-11T06:09:59.868037Z",
     "shell.execute_reply.started": "2024-02-11T06:09:45.931258Z",
     "shell.execute_reply": "2024-02-11T06:09:59.867072Z"
    },
    "trusted": true,
    "id": "atSHt0mKgMOB"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ***Bow Result:***\n",
    "mô hình phân loại đã đạt được độ chính xác 86% trên tập dữ liệu, cho thấy rằng nó đã phân loại chính xác 86% trường hợp, mặc dù độ chính xác cho thấy mô hình đã hoạt động tốt, hãy xem xét sự sai lệch.\n",
    "\n",
    "Khi xem xét ma trận nhầm lẫn, chúng tôi nhận thấy rằng trong số các trường hợp dương tính thực tế, mô hình đã dự đoán chính xác 1.787 là dương tính (dương tính thật), nhưng lại phân loại sai 75 là âm tính (âm tính giả). Ngoài ra, trong số các trường hợp âm tính thực tế, mô hình đã dự đoán chính xác 26 là âm tính (âm tính thật), trong khi phân loại sai 214 là dương tính (dương tính giả).\n",
    "\n",
    "Độ chính xác của lớp dương tính là 89%, cho thấy rằng trong số tất cả các trường hợp được dự đoán là dương tính thì 89% thực sự là dương tính. Tỷ lệ thu hồi đối với lớp tích cực là 96%, cho thấy mô hình đã xác định chính xác 96% trường hợp tích cực. Điểm f1 cho lớp tích cực là 93%, kết hợp độ chính xác và khả năng thu hồi thành một số liệu duy nhất và điều này cho thấy rằng mô hình dự đoán lớp tích cực thực sự tốt.\n",
    "\n",
    "Mặt khác, độ chính xác của lớp âm tương đối thấp ở mức 28%, ngụ ý rằng chỉ 28% trường hợp được dự đoán là âm là thực sự âm. Tỷ lệ thu hồi đối với lớp phủ định là 12%, cho thấy mô hình đã gặp khó khăn trong việc xác định chính xác các trường hợp phủ định. Điểm f1 cho lớp phủ định là 17%. Điều này cho thấy rằng mô hình của chúng tôi rất kém trong việc dự đoán loại hoặc đánh giá tiêu cực."
   ],
   "metadata": {
    "id": "CPweyojBgMOC"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Để chẩn đoán sự cố, chúng tôi có thể sử dụng nhiều kỹ thuật khác nhau nhưng hãy trực quan hóa dữ liệu đào tạo của chúng tôi ở dạng 2D để hiểu rõ hơn mức độ phân tách giữa các đánh giá tích cực và tiêu cực.",
   "metadata": {
    "id": "FfQdbInAgMOC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# visualizing BOW with TSNE\n",
    "\n",
    "title = 'Bag of Words'\n",
    "tsne_visualizer(data=X_train_bow_pca, label=y_train, title=title)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:09:59.869042Z",
     "iopub.execute_input": "2024-02-11T06:09:59.869708Z",
     "iopub.status.idle": "2024-02-11T06:11:39.209744Z",
     "shell.execute_reply.started": "2024-02-11T06:09:59.869607Z",
     "shell.execute_reply": "2024-02-11T06:11:39.208461Z"
    },
    "trusted": true,
    "id": "eMFkm_c5gMOC"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (B) TF-IDF"
   ],
   "metadata": {
    "id": "l-hcUV9wgMOC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# TF-IDF\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "train_tfidf = vectorizer_tfidf.fit_transform(df_train['CleanedText'].values)\n",
    "cv_tfidf = vectorizer_tfidf.transform(df_cv['CleanedText'].values)\n",
    "test_tfidf = vectorizer_tfidf.transform(df_test['CleanedText'].values)\n",
    "\n",
    "print(train_tfidf.shape)\n",
    "print(cv_tfidf.shape)\n",
    "print(test_tfidf.shape)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:11:39.211557Z",
     "iopub.execute_input": "2024-02-11T06:11:39.212797Z",
     "iopub.status.idle": "2024-02-11T06:11:39.663587Z",
     "shell.execute_reply.started": "2024-02-11T06:11:39.212749Z",
     "shell.execute_reply": "2024-02-11T06:11:39.662392Z"
    },
    "trusted": true,
    "id": "zNHm3KI4gMOC"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "## OVERSAMPLING\n",
    "\n",
    "# plotting class imbalance before oversampling\n",
    "plt.figure(1, figsize=(17,6))\n",
    "plt.subplot(1,2,1)\n",
    "sns.countplot(x=df_train['Score'])\n",
    "plt.title('class distribution before oversampling')\n",
    "print('Shape of data before oversampling:', train_tfidf.shape, '\\n\\n')\n",
    "\n",
    "# performing oversampling using smote\n",
    "# oversampling our train data\n",
    "ros = RandomOverSampler()\n",
    "X_train_tfidf, Y_train_tfidf = ros.fit_resample(train_tfidf,df_train['Score'])\n",
    "\n",
    "# plotting class dist after oversampling\n",
    "plt.subplot(1,2,2)\n",
    "sns.countplot(x=Y_train_tfidf)\n",
    "plt.title('class distribution after oversampling')\n",
    "plt.show()\n",
    "print('Shape of data after oversampling:', X_train_tfidf.shape)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:11:39.664915Z",
     "iopub.execute_input": "2024-02-11T06:11:39.665275Z",
     "iopub.status.idle": "2024-02-11T06:11:40.186538Z",
     "shell.execute_reply.started": "2024-02-11T06:11:39.665243Z",
     "shell.execute_reply": "2024-02-11T06:11:40.185204Z"
    },
    "trusted": true,
    "id": "SRvYDuaAgMOC"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# standardization\n",
    "scaler_tfidf = StandardScaler()\n",
    "X_train_tfidf_standardised = scaler_tfidf.fit_transform(X_train_tfidf.toarray())\n",
    "X_cv_tfidf_standardised = scaler_tfidf.transform(cv_tfidf.toarray())\n",
    "X_test_tfidf_standardised = scaler_tfidf.transform(test_tfidf.toarray())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:11:40.187867Z",
     "iopub.execute_input": "2024-02-11T06:11:40.188212Z",
     "iopub.status.idle": "2024-02-11T06:11:43.063597Z",
     "shell.execute_reply.started": "2024-02-11T06:11:40.188181Z",
     "shell.execute_reply": "2024-02-11T06:11:43.062164Z"
    },
    "trusted": true,
    "id": "G1okpthXgMOC"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# dim reduction using PCA. We can also use truncated SVD\n",
    "\n",
    "pca = PCA(n_components=3000)\n",
    "pca.fit(X_train_tfidf_standardised)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(len(explained_variance))\n",
    "\n",
    "\n",
    "dim_req_var = sum(np.cumsum(explained_variance) <=0.95)\n",
    "print('Dimensions required for 95 percent explained variance:', dim_req_var)\n",
    "print('Variance Explained:', np.cumsum(explained_variance)[dim_req_var])\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.grid()\n",
    "plt.plot(list(range(len(explained_variance))),np.cumsum(explained_variance))\n",
    "plt.axvline(x = dim_req_var, color = 'g', label='95 pecent var line')\n",
    "plt.xlabel('Dimensions')\n",
    "plt.ylabel('Cumulative Percentage Variance Explained')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "X_train_tfidf_pca = pca.transform(X_train_tfidf_standardised)[:, :dim_req_var]\n",
    "X_cv_tfidf_pca = pca.transform(X_cv_tfidf_standardised)[:, :dim_req_var]\n",
    "X_test_tfidf_pca = pca.transform(X_test_tfidf_standardised)[:, :dim_req_var]\n",
    "\n",
    "y_train = Y_train_tfidf\n",
    "y_cv = df_cv['Score'].values\n",
    "y_test = df_test['Score'].values"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:11:43.065306Z",
     "iopub.execute_input": "2024-02-11T06:11:43.065815Z",
     "iopub.status.idle": "2024-02-11T06:14:13.388561Z",
     "shell.execute_reply.started": "2024-02-11T06:11:43.065771Z",
     "shell.execute_reply": "2024-02-11T06:14:13.386905Z"
    },
    "trusted": true,
    "id": "xVrk6UDmgMOF"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Using KNN for classification\n",
    "accuracy = []\n",
    "f1_positive = []\n",
    "f1_negative = []\n",
    "K_values = list(range(1,30,2))\n",
    "\n",
    "for k in tqdm(K_values):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_tfidf_pca, y_train)\n",
    "    pred = knn.predict(X_cv_tfidf_pca)\n",
    "    f1_positive.append(f1_score(y_cv, pred, pos_label=\"positive\"))\n",
    "    f1_negative.append(f1_score(y_cv, pred, pos_label=\"negative\"))\n",
    "    accuracy.append(accuracy_score(y_cv, pred))\n",
    "\n",
    "positive_ind = f1_positive.index(max(f1_positive))\n",
    "negative_ind = f1_negative.index(max(f1_negative))\n",
    "acc_ind = accuracy.index(max(accuracy))\n",
    "print('The maximum accuracy is {a} with K value of {b}'.format(a=max(accuracy), b=K_values[acc_ind]))\n",
    "print('The maximum F1 score on CV data for positive labels is {a} with K value of {b}'.format(a=max(f1_positive), b=K_values[positive_ind]))\n",
    "print('The maximum F1 score on CV data for negative labels is {a} with K value of {b}'.format(a=max(f1_negative), b=K_values[negative_ind]))\n",
    "\n",
    "# plotting accuracy f1-positive and f1-negative for K values\n",
    "plt.figure(1, figsize=(22,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(K_values, accuracy, 'o--')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('K_Values')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(K_values, f1_positive, 'o--')\n",
    "plt.title('F1_Positive')\n",
    "plt.xlabel('K_Values')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(K_values, f1_negative, 'o--')\n",
    "plt.title('F1_Negative')\n",
    "plt.xlabel('K_Values')\n",
    "\n",
    "# knn on our test data for reporting\n",
    "# plase note that we can fit it on best value of our negativef1 score as well\n",
    "# in order to boost the precision and recall for our negative reviews\n",
    "knn = KNeighborsClassifier(n_neighbors=K_values[acc_ind])\n",
    "knn.fit(X_train_tfidf_pca, y_train)\n",
    "pred = knn.predict(X_test_tfidf_pca)\n",
    "\n",
    "# generating relevant martices\n",
    "confusion_mat = pd.DataFrame(confusion_matrix(y_test, pred, labels=['positive', 'negative']), columns=['pred_positive', 'pred_negative'], index=['true_positive', 'true_negative'])\n",
    "print('\\nConfusion matrix:')\n",
    "print(confusion_mat)\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, pred))\n",
    "print('\\nAccuracy on Test Data:', accuracy_score(y_test, pred))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:14:13.391537Z",
     "iopub.execute_input": "2024-02-11T06:14:13.392569Z",
     "iopub.status.idle": "2024-02-11T06:14:29.747263Z",
     "shell.execute_reply.started": "2024-02-11T06:14:13.392501Z",
     "shell.execute_reply": "2024-02-11T06:14:29.746356Z"
    },
    "trusted": true,
    "id": "pLqlB2YogMOF"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ***Kết quả TFIDF:***\n",
    "Mô hình phân loại đạt được độ chính xác 88,0% trên dữ liệu thử nghiệm, cho thấy nó đã phân loại chính xác 88,0% số trường hợp.\n",
    "\n",
    "Kiểm tra ma trận nhầm lẫn, chúng tôi nhận thấy rằng trong số các trường hợp dương tính thực tế, mô hình đã dự đoán chính xác 1.835 là dương tính (dương tính thật), nhưng nó đã phân loại sai 25 trường hợp là âm tính (âm tính giả). Tương tự, đối với các trường hợp âm tính thực tế, mô hình đã dự đoán chính xác 4 là âm tính (âm tính thật), nhưng nó đã phân loại sai 236 trường hợp là dương tính (dương tính giả).\n",
    "\n",
    "Độ chính xác của lớp dương tính là 89%, cho thấy rằng trong số tất cả các trường hợp được dự đoán là dương tính thì 89% thực sự là dương tính. Tỷ lệ thu hồi đối với lớp tích cực là 99%, cho thấy mô hình đã xác định chính xác 99% trường hợp tích cực. Điểm f1 cho lớp tích cực là 93%, kết hợp độ chính xác và khả năng thu hồi thành một số liệu duy nhất.\n",
    "\n",
    "Mặt khác, độ chính xác của lớp âm thực sự thấp ở mức 14%, ngụ ý rằng chỉ 14% trường hợp được dự đoán là âm là thực sự âm. Tỷ lệ thu hồi đối với lớp phủ định là 2%, cho thấy mô hình đã gặp khó khăn trong việc xác định chính xác các trường hợp phủ định. Điểm f1 cho lớp phủ định là 3%. Nhìn chung, mô hình này về cơ bản hoạt động như một mô hình ngu ngốc, phân loại từng điểm là tích cực và hoạt động kém hơn mô hình BOW.\n",
    "\n",
    "Chúng ta có thể sử dụng thước đo khác như Điểm F1 cho lớp phủ định để xác định K tốt nhất nhằm tăng cường dự đoán về lớp phủ định."
   ],
   "metadata": {
    "id": "P9cLls-xgMOF"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Để chẩn đoán sự cố, chúng tôi có thể sử dụng nhiều kỹ thuật khác nhau nhưng hãy trực quan hóa dữ liệu đào tạo của chúng tôi ở dạng 2D để hiểu rõ hơn mức độ phân tách giữa các đánh giá tích cực và tiêu cực.",
   "metadata": {
    "id": "PIkgruvLgMOG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# visualizing TFIDF train data with TSNE\n",
    "\n",
    "title = 'TF-IDF'\n",
    "tsne_visualizer(data=X_train_tfidf_pca, label=y_train, title=title)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:14:29.748787Z",
     "iopub.execute_input": "2024-02-11T06:14:29.74942Z",
     "iopub.status.idle": "2024-02-11T06:16:13.083827Z",
     "shell.execute_reply.started": "2024-02-11T06:14:29.749373Z",
     "shell.execute_reply": "2024-02-11T06:16:13.081872Z"
    },
    "trusted": true,
    "id": "LwKbFi0hgMOG"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Chuyển đổi văn bản sang vectơ với Word2Vec\n",
    "***Word2Vec:*** Word2Vec là một thuật toán được sử dụng rộng rãi trong xử lý ngôn ngữ tự nhiên (NLP) để tìm hiểu cách nhúng từ, là những cách biểu thị dày đặc của các từ bằng số. Nó dựa trên ý tưởng rằng những từ có nghĩa tương tự nhau thường xuất hiện trong những ngữ cảnh tương tự nhau. Word2Vec nắm bắt các mối quan hệ này bằng cách học cách dự đoán một từ dựa trên các từ lân cận của nó hoặc dự đoán các từ lân cận dựa trên một từ nhất định. Có hai cách chúng tôi sẽ sử dụng Word2Vec để chuyển đổi câu của mình\n",
    "\n",
    "1. ***Word2Vec trung bình:*** Trong trường hợp Word2Vec trung bình, mục tiêu là tạo biểu diễn vectơ có độ dài cố định cho tài liệu bằng cách lấy trung bình các vectơ từ của tất cả các từ trong tài liệu.\n",
    "\n",
    "2. ***Word2Vec có trọng số TF-IDF:*** Word2Vec có trọng số TF-IDF kết hợp các khái niệm của TF-IDF và Word2Vec để tạo các phần nhúng từ nắm bắt cả ý nghĩa ngữ nghĩa của các từ và tầm quan trọng của chúng trong kho tài liệu. Nó cải tiến mô hình Word2Vec truyền thống bằng cách kết hợp sơ đồ trọng số tần số tài liệu nghịch đảo tần số (TF-IDF)."
   ],
   "metadata": {
    "id": "Ea5genGZgMOG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (C) Average Word2Vec"
   ],
   "metadata": {
    "id": "loSBoXdDgMOG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:16:13.085466Z",
     "iopub.execute_input": "2024-02-11T06:16:13.085904Z",
     "iopub.status.idle": "2024-02-11T06:16:13.367611Z",
     "shell.execute_reply.started": "2024-02-11T06:16:13.085871Z",
     "shell.execute_reply": "2024-02-11T06:16:13.366409Z"
    },
    "trusted": true,
    "id": "nCM5UH71gMOG"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from gensim.models import Word2Vec as gensim_Word2Vec\n",
    "\n",
    "def Word2Vec(sentences, vector_size=100, window=5, min_count=1, epochs=10, learning_rate=0.01, workers=1):\n",
    "    # Tạo một đối tượng Word2Vec từ Gensim\n",
    "    model = gensim_Word2Vec(sentences, vector_size=vector_size, window=window, min_count=min_count, epochs=epochs, workers=workers)\n",
    "\n",
    "    # Trả về các vector nhúng của từ điển\n",
    "    trained_embeddings = model.wv.vectors\n",
    "    word2idx = {word: idx for idx, word in enumerate(model.wv.index_to_key)}\n",
    "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "\n",
    "    return trained_embeddings, word2idx, idx2word\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# we have already cleaned our reviews for Word2Vec\n",
    "# now generate the data-structure suitable for the input of Word2Vec model\n",
    "# required data structure => [[this], [is], [a], [review]]\n",
    "\n",
    "def datastructure_generator_w2v(df):\n",
    "    list_of_reviews = []\n",
    "    for sent in tqdm(df['CleanedText_w2v'].values):\n",
    "        list_of_reviews.append(sent.split())\n",
    "    return list_of_reviews"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:16:13.369168Z",
     "iopub.execute_input": "2024-02-11T06:16:13.369596Z",
     "iopub.status.idle": "2024-02-11T06:16:13.376019Z",
     "shell.execute_reply.started": "2024-02-11T06:16:13.369565Z",
     "shell.execute_reply": "2024-02-11T06:16:13.374798Z"
    },
    "trusted": true,
    "id": "pHysOj_QgMOG"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# constructing required structures\n",
    "\n",
    "list_of_sent =  datastructure_generator_w2v(final)\n",
    "list_of_sent_train =  datastructure_generator_w2v(df_train)\n",
    "list_of_sent_cv = datastructure_generator_w2v(df_cv)\n",
    "list_of_sent_test = datastructure_generator_w2v(df_test)\n",
    "avg_w2v_data_dict = {'train':list_of_sent_train, 'cv':list_of_sent_cv, 'test':list_of_sent_test}\n",
    "\n",
    "list_of_sent_idf_train = df_train['CleanedText_w2v']\n",
    "list_of_sent_idf_cv = df_cv['CleanedText_w2v']\n",
    "list_of_sent_idf_test = df_test['CleanedText_w2v']\n",
    "\n",
    "print('Done..!!')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:16:13.378049Z",
     "iopub.execute_input": "2024-02-11T06:16:13.378505Z",
     "iopub.status.idle": "2024-02-11T06:16:19.487718Z",
     "shell.execute_reply.started": "2024-02-11T06:16:13.37847Z",
     "shell.execute_reply": "2024-02-11T06:16:19.486931Z"
    },
    "trusted": true,
    "id": "RaLm3t19gMOG"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# training Word2Vec model on our data\n",
    "# this may take time to execute\n",
    "model_w2v=Word2Vec(list_of_sent,min_count=5,vector_size=50, workers=2)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:16:19.489478Z",
     "iopub.execute_input": "2024-02-11T06:16:19.489836Z",
     "iopub.status.idle": "2024-02-11T06:18:43.999179Z",
     "shell.execute_reply.started": "2024-02-11T06:16:19.489807Z",
     "shell.execute_reply": "2024-02-11T06:18:43.99797Z"
    },
    "trusted": true,
    "id": "2qpNRgJEgMOG"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# construct avg w2v\n",
    "\n",
    "vocabulary_w2v = model_w2v.wv.key_to_index.keys()\n",
    "avg_w2v_data_dict_final = {'train':None, 'cv':None, 'test':None}\n",
    "\n",
    "for key,item in avg_w2v_data_dict.items():\n",
    "    print(key)\n",
    "    review_vectors_w2v = []\n",
    "\n",
    "    for sentence in tqdm(item):\n",
    "        word_count = 0\n",
    "        sent_vec = np.zeros(shape=50)\n",
    "        for word in sentence:\n",
    "            if word in vocabulary_w2v:\n",
    "                sent_vec += model_w2v.wv[word]\n",
    "                word_count += 1\n",
    "\n",
    "        if word_count != 0:\n",
    "            sent_vec = sent_vec/word_count\n",
    "        review_vectors_w2v.append(sent_vec)\n",
    "    review_vectors_w2v = np.array(review_vectors_w2v)\n",
    "    print(review_vectors_w2v.shape)\n",
    "    avg_w2v_data_dict_final[key] = review_vectors_w2v"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:18:44.009218Z",
     "iopub.execute_input": "2024-02-11T06:18:44.009674Z",
     "iopub.status.idle": "2024-02-11T06:18:46.36598Z",
     "shell.execute_reply.started": "2024-02-11T06:18:44.00964Z",
     "shell.execute_reply": "2024-02-11T06:18:46.364846Z"
    },
    "trusted": true,
    "id": "iWMl8-5RgMOG"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# sanity check\n",
    "for key,item in avg_w2v_data_dict_final.items():\n",
    "    print(key)\n",
    "    print(item.shape)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:18:46.368273Z",
     "iopub.execute_input": "2024-02-11T06:18:46.368629Z",
     "iopub.status.idle": "2024-02-11T06:18:46.375027Z",
     "shell.execute_reply.started": "2024-02-11T06:18:46.368602Z",
     "shell.execute_reply": "2024-02-11T06:18:46.373826Z"
    },
    "trusted": true,
    "id": "zkVfHXL8gMOG"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# creating reference for ease of access\n",
    "avg_w2v_data_train = avg_w2v_data_dict_final['train']\n",
    "avg_w2v_data_cv = avg_w2v_data_dict_final['cv']\n",
    "avg_w2v_data_test = avg_w2v_data_dict_final['test']"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:18:46.376976Z",
     "iopub.execute_input": "2024-02-11T06:18:46.377477Z",
     "iopub.status.idle": "2024-02-11T06:18:46.38753Z",
     "shell.execute_reply.started": "2024-02-11T06:18:46.377434Z",
     "shell.execute_reply": "2024-02-11T06:18:46.386583Z"
    },
    "trusted": true,
    "id": "2ld_PvXTgMOG"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "## OVERSAMPLING\n",
    "\n",
    "# plotting class imbalance before oversampling\n",
    "plt.figure(1, figsize=(17,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('class distribution before oversampling')\n",
    "sns.countplot(x=df_train['Score'])\n",
    "print('Shape of data before oversampling:', avg_w2v_data_train.shape, '\\n\\n')\n",
    "\n",
    "# performing oversampling using smote\n",
    "# oversampling our train data\n",
    "ros = RandomOverSampler()\n",
    "avg_w2v_data_train, Y_avg_w2v_data_train = ros.fit_resample(avg_w2v_data_train,df_train['Score'])\n",
    "\n",
    "# plotting class dist after oversampling\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('class distribution after oversampling')\n",
    "sns.countplot(x=Y_avg_w2v_data_train)\n",
    "plt.show()\n",
    "print('Shape of data after oversampling:', avg_w2v_data_train.shape)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:18:46.388723Z",
     "iopub.execute_input": "2024-02-11T06:18:46.38911Z",
     "iopub.status.idle": "2024-02-11T06:18:46.92104Z",
     "shell.execute_reply.started": "2024-02-11T06:18:46.389077Z",
     "shell.execute_reply": "2024-02-11T06:18:46.919945Z"
    },
    "trusted": true,
    "id": "jZ8pgQmXgMOG"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# standardization\n",
    "scaler_avg_w2v = StandardScaler()\n",
    "X_train_avg_w2v_standardised = scaler_avg_w2v.fit_transform(avg_w2v_data_train)\n",
    "X_cv_avg_w2v_standardised = scaler_avg_w2v.transform(avg_w2v_data_cv)\n",
    "X_test_avg_w2v_standardised = scaler_avg_w2v.transform(avg_w2v_data_test)\n",
    "\n",
    "y_train = Y_avg_w2v_data_train\n",
    "y_cv = df_cv['Score'].values\n",
    "y_test = df_test['Score'].values"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:18:46.922728Z",
     "iopub.execute_input": "2024-02-11T06:18:46.923063Z",
     "iopub.status.idle": "2024-02-11T06:18:46.93605Z",
     "shell.execute_reply.started": "2024-02-11T06:18:46.923034Z",
     "shell.execute_reply": "2024-02-11T06:18:46.935064Z"
    },
    "trusted": true,
    "id": "U4KYbZzCgMOG"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Using KNN for classification\n",
    "accuracy = []\n",
    "f1_positive = []\n",
    "f1_negative = []\n",
    "K_values = list(range(1,30,2))\n",
    "\n",
    "for k in tqdm(K_values):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_avg_w2v_standardised, y_train)\n",
    "    pred = knn.predict(X_cv_avg_w2v_standardised)\n",
    "    f1_positive.append(f1_score(y_cv, pred, pos_label=\"positive\"))\n",
    "    f1_negative.append(f1_score(y_cv, pred, pos_label=\"negative\"))\n",
    "    accuracy.append(accuracy_score(y_cv, pred))\n",
    "\n",
    "positive_ind = f1_positive.index(max(f1_positive))\n",
    "negative_ind = f1_negative.index(max(f1_negative))\n",
    "acc_ind = accuracy.index(max(accuracy))\n",
    "print('The maximum accuracy is {a} with K value of {b}'.format(a=max(accuracy), b=K_values[acc_ind]))\n",
    "print('The maximum F1 score on CV data for positive labels is {a} with K value of {b}'.format(a=max(f1_positive), b=K_values[positive_ind]))\n",
    "print('The maximum F1 score on CV data for negative labels is {a} with K value of {b}'.format(a=max(f1_negative), b=K_values[negative_ind]))\n",
    "\n",
    "# plotting accuracy f1-positive and f1-negative for K values\n",
    "plt.figure(1, figsize=(22,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(K_values, accuracy, 'o--')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('K_Values')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(K_values, f1_positive, 'o--')\n",
    "plt.title('F1_Positive')\n",
    "plt.xlabel('K_Values')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(K_values, f1_negative, 'o--')\n",
    "plt.title('F1_Negative')\n",
    "plt.xlabel('K_Values')\n",
    "\n",
    "# knn on our test data for reporting\n",
    "# plase note that we can fit it on best value of our negativef1 score as well\n",
    "# in order to boost the precision and recall for our negative reviews\n",
    "knn = KNeighborsClassifier(n_neighbors=K_values[acc_ind])\n",
    "knn.fit(X_train_avg_w2v_standardised, y_train)\n",
    "pred = knn.predict(X_test_avg_w2v_standardised)\n",
    "\n",
    "# generating relevant martices\n",
    "confusion_mat = pd.DataFrame(confusion_matrix(y_test, pred, labels=['positive', 'negative']), columns=['pred_positive', 'pred_negative'], index=['true_positive', 'true_negative'])\n",
    "print('\\nConfusion matrix:')\n",
    "print(confusion_mat)\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, pred))\n",
    "print('\\nAccuracy on Test Data:', accuracy_score(y_test, pred))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:18:46.937488Z",
     "iopub.execute_input": "2024-02-11T06:18:46.938039Z",
     "iopub.status.idle": "2024-02-11T06:18:50.215727Z",
     "shell.execute_reply.started": "2024-02-11T06:18:46.938007Z",
     "shell.execute_reply": "2024-02-11T06:18:50.214686Z"
    },
    "trusted": true,
    "id": "uqTy24sZgMOG"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ***Average Word2Vector Results:***\n",
    "\n",
    "The classification model achieved an accuracy of 88% on the test data, indicating that it correctly classified 88% of the instances.\n",
    "\n",
    "Analyzing the confusion matrix, we observe that out of the actual positive instances, the model correctly predicted 1,762 as positive (true positive), but it misclassified 98 instances as negative (false negative). Similarly, for the actual negative instances, the model correctly predicted 78 as negative (true negative), while misclassifying 162 instances as positive (false positive).\n",
    "\n",
    "The precision for the positive class is 92%, suggesting that out of all instances predicted as positive, 92% were actually positive. The recall for the positive class is 95%, indicating that the model accurately identified 95% of the positive instances. The f1-score for the positive class is 93%, which combines precision and recall into a single metric.\n",
    "\n",
    "On the other hand, the precision for the negative class is 44%, implying that only 44% of the instances predicted as negative were truly negative. The recall for the negative class is 33%, indicating that the model struggled to correctly identify the negative instances. The f1-score for the negative class is 38%.\n",
    "\n",
    "Overall this model performs better than our previous models. We can see that the reviews are better seperated in the visualization below as well."
   ],
   "metadata": {
    "id": "oYkcNcMNgMOG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# visualizing average word2vec with TSNE\n",
    "\n",
    "title = 'Average Word2Vec'\n",
    "tsne_visualizer(data=X_train_avg_w2v_standardised, label=y_train, title=title)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:18:50.217093Z",
     "iopub.execute_input": "2024-02-11T06:18:50.217913Z",
     "iopub.status.idle": "2024-02-11T06:20:15.163727Z",
     "shell.execute_reply.started": "2024-02-11T06:18:50.21787Z",
     "shell.execute_reply": "2024-02-11T06:20:15.162317Z"
    },
    "trusted": true,
    "id": "iAlEfXzpgMOG"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TF-IDF Weighted Word2Vec"
   ],
   "metadata": {
    "id": "dDEBrG31gMOG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# generating tfidf values\n",
    "vectorizer_tfidf_w2v = TfidfVectorizer()\n",
    "tfidf_data_w2v_train = vectorizer_tfidf_w2v.fit_transform(list_of_sent_idf_train)\n",
    "tfidf_data_w2v_cv = vectorizer_tfidf_w2v.transform(list_of_sent_idf_cv)\n",
    "tfidf_data_w2v_test = vectorizer_tfidf_w2v.transform(list_of_sent_idf_test)\n",
    "\n",
    "tfidf_values_dict = {'train':tfidf_data_w2v_train, 'cv':tfidf_data_w2v_cv, 'test':tfidf_data_w2v_test}"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-11T06:20:15.165107Z",
     "iopub.execute_input": "2024-02-11T06:20:15.165835Z"
    },
    "trusted": true,
    "id": "RuEsf9vEgMOG"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# constructing tf-idf weighted Word2Vec\n",
    "\n",
    "tfidf_feature_names = list(vectorizer_tfidf_w2v.get_feature_names_out())\n",
    "tfidf_w2v_data_dict_final = {'train':None, 'cv':None, 'test':None}\n",
    "\n",
    "for key,item in avg_w2v_data_dict.items():\n",
    "    print(key)\n",
    "    w2v_tfidf_data = []\n",
    "\n",
    "    for i,sentence in enumerate(tqdm(item)):\n",
    "        tfidf_weight = 0\n",
    "        sent_vec = np.zeros(shape=50)\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                tfidf_value = tfidf_values_dict[key][i,tfidf_feature_names.index(word)]\n",
    "                # print(tfidf_value)\n",
    "                w2v_vector = model_w2v.wv[word]\n",
    "                sent_vec += tfidf_value * w2v_vector\n",
    "                tfidf_weight += tfidf_value\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        sent_vec = sent_vec / tfidf_weight\n",
    "        w2v_tfidf_data.append(sent_vec)\n",
    "    w2v_tfidf_data = np.array(w2v_tfidf_data)\n",
    "    print(w2v_tfidf_data.shape)\n",
    "    tfidf_w2v_data_dict_final[key] = w2v_tfidf_data"
   ],
   "metadata": {
    "trusted": true,
    "id": "l2ZavhIFgMOH"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# sanity check\n",
    "for key,item in tfidf_w2v_data_dict_final.items():\n",
    "    print(key)\n",
    "    print(item.shape)"
   ],
   "metadata": {
    "trusted": true,
    "id": "ZvOyCS8ggMOH"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "tfidf_w2v_data_train = tfidf_w2v_data_dict_final['train']\n",
    "tfidf_w2v_data_cv = tfidf_w2v_data_dict_final['cv']\n",
    "tfidf_w2v_data_test = tfidf_w2v_data_dict_final['test']"
   ],
   "metadata": {
    "trusted": true,
    "id": "r1XVwMirgMOH"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# dropping any NA values if present\n",
    "tfidf_w2v_data_test"
   ],
   "metadata": {
    "trusted": true,
    "id": "ILEEMiCRgMOH"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "## OVERSAMPLING\n",
    "\n",
    "# plotting class imbalance before oversampling\n",
    "plt.figure(1, figsize=(17,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('class distribution before oversampling')\n",
    "sns.countplot(x=df_train['Score'])\n",
    "print('Shape of data before oversampling:', tfidf_w2v_data_train.shape, '\\n\\n')\n",
    "\n",
    "# performing oversampling using smote\n",
    "# oversampling our train data\n",
    "ros = RandomOverSampler()\n",
    "tfidf_w2v_data_train, Y_tfidf_w2v_data_train = ros.fit_resample(tfidf_w2v_data_train,df_train['Score'])\n",
    "\n",
    "# plotting class dist after oversampling\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('class distribution after oversampling')\n",
    "sns.countplot(x=Y_tfidf_w2v_data_train)\n",
    "plt.show()\n",
    "print('Shape of data after oversampling:', tfidf_w2v_data_train.shape)\n"
   ],
   "metadata": {
    "trusted": true,
    "id": "T--5zC17gMOH"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# standardization\n",
    "scaler_tfidf_w2v = StandardScaler()\n",
    "X_train_tfidf_w2v_standardised = scaler_tfidf_w2v.fit_transform(tfidf_w2v_data_train)\n",
    "X_cv_tfidf_w2v_standardised = scaler_tfidf_w2v.transform(tfidf_w2v_data_cv)\n",
    "X_test_tfidf_w2v_standardised = scaler_tfidf_w2v.transform(tfidf_w2v_data_test)\n",
    "\n",
    "y_train = Y_tfidf_w2v_data_train\n",
    "y_cv = df_cv['Score'].values\n",
    "y_test = df_test['Score'].values"
   ],
   "metadata": {
    "trusted": true,
    "id": "9Q1d0nMzgMOH"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Using KNN for classification\n",
    "accuracy = []\n",
    "f1_positive = []\n",
    "f1_negative = []\n",
    "K_values = list(range(1,30,2))\n",
    "\n",
    "for k in tqdm(K_values):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_tfidf_w2v_standardised, y_train)\n",
    "    pred = knn.predict(X_cv_tfidf_w2v_standardised)\n",
    "    f1_positive.append(f1_score(y_cv, pred, pos_label=\"positive\"))\n",
    "    f1_negative.append(f1_score(y_cv, pred, pos_label=\"negative\"))\n",
    "    accuracy.append(accuracy_score(y_cv, pred))\n",
    "\n",
    "positive_ind = f1_positive.index(max(f1_positive))\n",
    "negative_ind = f1_negative.index(max(f1_negative))\n",
    "acc_ind = accuracy.index(max(accuracy))\n",
    "print('The maximum accuracy is {a} with K value of {b}'.format(a=max(accuracy), b=K_values[acc_ind]))\n",
    "print('The maximum F1 score on CV data for positive labels is {a} with K value of {b}'.format(a=max(f1_positive), b=K_values[positive_ind]))\n",
    "print('The maximum F1 score on CV data for negative labels is {a} with K value of {b}'.format(a=max(f1_negative), b=K_values[negative_ind]))\n",
    "\n",
    "# plotting accuracy f1-positive and f1-negative for K values\n",
    "plt.figure(1, figsize=(22,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(K_values, accuracy, 'o--')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('K_Values')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(K_values, f1_positive, 'o--')\n",
    "plt.title('F1_Positive')\n",
    "plt.xlabel('K_Values')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(K_values, f1_negative, 'o--')\n",
    "plt.title('F1_Negative')\n",
    "plt.xlabel('K_Values')\n",
    "\n",
    "# knn on our test data for reporting\n",
    "knn = KNeighborsClassifier(n_neighbors=K_values[acc_ind])\n",
    "knn.fit(X_train_tfidf_w2v_standardised, y_train)\n",
    "pred = knn.predict(X_test_tfidf_w2v_standardised)\n",
    "\n",
    "# generating relevant martices\n",
    "confusion_mat = pd.DataFrame(confusion_matrix(y_test, pred, labels=['positive', 'negative']), columns=['pred_positive', 'pred_negative'], index=['true_positive', 'true_negative'])\n",
    "print('\\nConfusion matrix:')\n",
    "print(confusion_mat)\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, pred))\n",
    "print('\\nAccuracy on Test Data:', accuracy_score(y_test, pred))"
   ],
   "metadata": {
    "trusted": true,
    "id": "OSYhXWX6gMOH"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ***TF-IDF Weighted Word2Vector Results:***\n",
    "\n",
    "The classification model achieved an accuracy of 86% on the test data, indicating that it correctly classified 86% of the instances.\n",
    "\n",
    "Analyzing the confusion matrix, we observe that out of the actual positive instances, the model correctly predicted 1,728 as positive (true positive), but it misclassified 132 instances as negative (false negative). Similarly, for the actual negative instances, the model correctly predicted 85 as negative (true negative), while misclassifying 155 instances as positive (false positive).\n",
    "\n",
    "The precision for the positive class is 92%, suggesting that out of all instances predicted as positive, 92% were actually positive. The recall for the positive class is 93%, indicating that the model accurately identified 93% of the positive instances. The f1-score for the positive class is 92%, which combines precision and recall into a single metric.\n",
    "\n",
    "On the other hand, the precision for the negative class is 39%, implying that only 39% of the instances predicted as negative were truly negative. The recall for the negative class is 35%, indicating that the model struggled to correctly identify the negative instances. The f1-score for the negative class is 37%.\n"
   ],
   "metadata": {
    "id": "S__3o2a4gMOH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# visualizing tfidf weighted word2vec with TSNE\n",
    "\n",
    "title = 'TF-IDF Word2Vec'\n",
    "tsne_visualizer(data=X_train_tfidf_w2v_standardised, label=y_train, title=title)"
   ],
   "metadata": {
    "trusted": true,
    "id": "cuJ1NJ5PgMOH"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Results and Conclusion\n",
    "\n",
    "\n",
    "### Results\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "### Conclusion\n",
    "Mô hình BOW đạt độ chính xác 86% và cho thấy độ chính xác và khả năng thu hồi tương đối tốt đối với lớp tích cực. Tuy nhiên, nó hoạt động kém trong việc dự đoán lớp tiêu cực, với độ chính xác và điểm thu hồi thấp.\n",
    "\n",
    "Mô hình TFIDF đạt độ chính xác 88,0%, vượt trội một chút so với mô hình BOW. Tuy nhiên, việc dự đoán lớp âm kém hơn so với mô hình BOW.\n",
    "\n",
    "Mô hình Average Word2Vector cũng đạt độ chính xác 88%, cho thấy độ chính xác và điểm thu hồi tốt hơn đối với lớp tích cực so với các mô hình trước đó. nó gặp khó khăn trong việc dự đoán lớp âm nhưng cho thấy độ chính xác và khả năng thu hồi lớp âm tốt hơn so với hai mô hình trước đó.\n",
    "\n",
    "Mô hình Word2Vector có trọng số TFIDF hoạt động tương tự như mô hình W2V trung bình với độ chính xác là 86%. Nó cho thấy độ chính xác và khả năng thu hồi tương đối tốt đối với lớp dương, nó gặp khó khăn trong việc dự đoán lớp âm nhưng cho thấy độ chính xác và khả năng thu hồi tốt hơn đối với lớp âm so với các mô hình BOW và TFIDF.\n",
    "\n",
    "Về hiệu suất, mô hình Word2Vector trung bình và mô hình Word2Vec có trọng số TF-IDF cho kết quả tốt hơn so với hai mô hình còn lại. Tuy nhiên, tất cả các mô hình đều phải đối mặt với những thách thức trong việc dự đoán chính xác các trường hợp tiêu cực.\n",
    "\n",
    "Có thể thực hiện những cải tiến hơn nữa bằng cách khám phá các số liệu đánh giá khác, chẳng hạn như Điểm F1 cho lớp âm hoặc kiểm tra nếu dữ liệu huấn luyện và kiểm tra của chúng tôi tuân theo cùng một phân phối như trong phân tách dựa trên thời gian mà chúng tôi quan sát thấy vấn đề này.\n",
    "\n",
    "Word2Vector tốt hơn đáng kể so với hai vector hóa còn lại và chúng ta có thể thấy biểu diễn trực quan ở đây -> https://www.kaggle.com/code/raman007/amazon-finefood-review-directionality-reduction"
   ],
   "metadata": {
    "id": "S0QznnsAgMOH"
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ]
}
